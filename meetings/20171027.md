
PTP Meeting 27 Oct 2017
=======================

- Participants: Jonathan, Staffan (before lunch), Ola, Samuel

## Action points

- [ ] Read up on Norinder's paper on imbalanced datasetes in conformal
  prediction (Jonathan, and Samuel)
- [ ] Look closer at the "other" efficiency measure, available in:
  - Vovk, V., Fedorova, V., Nouretdinov, I., Gammerman, A., 2016. Criteria of
    efficiency for conformal prediction. In: Symposium on Conformal and
    Probabilistic Prediction with Applications. Springer, pp. 23â€“39.
- [ ] Samuel to start writing the methods section in manuscript.
- [ ] Next meeting: Probably on Monday, Oct 30

## Main conclusions

The main conclusion from the meeting was that it seems we might want to do a
PTP 1 and a PTP 2 project, like follows:

### PTP 1

- Journal aim: [Frontiers](https://www.frontiersin.org/research-topics/5898/chemoinformatics-approaches-to-structure--and-ligand-based-drug-design) (Deadline Nov 10)
- Exclude targets with fewer than 100 active or non-active
- Probably use the "new" efficiency measure, which is possible to use
  separately per class (active/nonactive)
- Preferrably do stratified cross-validation
- Perhaps fill up with presumed non-active compounds

... and PTP 2 like follows:

### PTP 2

- Journal aim: Unclear, but later
- Test whether compounds set as inactive in older ChEMBL versions show up as
  active ones in newer versions.
- Try to predict false nonactive ones, and remove from training?
- Try various strategies at managing small datasets:
  - Validate with leave-one-out instead of cross validation
  - Run libSVM instead of LIBLINEAR?
  - Run Venn-Abers to get ROC-curves?


## Other notes

- The `--proper-train` flag is used for the dataset that should not be included
  in calibration nor testing.
- The `--train` flags is for data that is used for both
  - Remaining question: So, it is used in neither calibration nor testing?
