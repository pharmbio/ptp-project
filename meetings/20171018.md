# PTP Meeting 18 Oct 2017

- Time: 11:15-12:00 ca
- Participants: Jonathan, Staffan, Ola, Samuel (via Hangout)

## Various notes and todos

- Samuel to start writing down the methods section of the paper (in the
  repo), and explaining in words what the workflow does, so as to allow review
  of these parts by others in the project.
- Samuel also to create summaries over the 44 targets/models ... stuff like:
  - Number of active ligands
  - Number of non-active ligands
  - Time to model with liblinear
  - Efficiency
  - Cost
  - Validity (Suggested by Ola ... we had a little discussion whether needed or
    not, but)
  - Efficiency/Validity of the final model too, not just the crossvalidated one?
- Ola to send list of Conformal Prediction papers to @samuell

## Questions and Answers

- How to do the efficiency averaging for selecting best cost/gamma?
  - Individually per target, or as an average value across all targets?
    - Answered before already: Per target

- Do we need to do any type of filtering of the data ... such as only selecting
  compounds with IC50/EC50 or ... values? ... or those with value over
  10microMolar? (Like in the TargetNet paper)
  - Answer: Should be already filtered in ExcapeDB

- Do we need to take any measures to guarantee that we have balance between
  positive and negative examples in our data?
  - No, we do mondrian CP already to account for that.
  - Might be good to plot the data set characteristics though.

- How many to run with libSVM?
  - Answer: We try to run everything with liblinear first, and then see how the efficiency etc looks.
  - Possibly put a breakpoint at 5k or 10k ligands.

- How many more genes?
  - Do the 44 (in the Bowes et al paper) and evaluate how much time it takes,
    etc, etc.
  - If we want, we could later take e.g. all targets that have data about more
    than 100 ligands, etc (which should be somewhere around 600).
