
# PTP Meeting 29 Sep 2017

Participants: Jonathan, Staffan, Samuel (and Ola, for 20 minutes at the end).

Since CVAP (Cross Venn-Abers Prediction) is not yet done, we will go with ACP
(Aggregated Conformal Prediction) instead.

(ACP being to randomly drawing a subset of the dataset for calibration(?) ...
and doing this multiple times and aggregating the multiple models into "one"
...  and doing this multiple times and aggregating the multiple models into
"one" ... if Samuel understood this correctly)

## A rough overview of the workflow to implement

### Get the ExcapeDB data

Done already. It is an 18Gb .tsv file.

Samuel did count the number of ligands bound to the 44 hazard-indicating target
proteins in [Bowes et al](http://www.nature.com/nrd/journal/v11/n12/abs/nrd3845.html), table 1.

They span from 40 ligands on the smallest one (KCNQ1), to 8617 on the largest
one (DRD2).

### Create one dataset per target

Create one dataset (in "tsv / smiles format") per target, out of those 44 in
the Bowes paper mentioned above.

CPSign takes a "smiles format" as input, which is basically a tsv type of
format with the following properties:

- SMILES should be in the first column
- Easiest if the value to be trained on is in second column (We will go with
  the "Activity flag" from the ExcapeDB data here, either using the existing
  "N" and "A" ids, or possibly changing to 0 and 1 ... but not -1, as that will
  create problems).
- We were discussing if we should put the gene name as the third column, but
  since we will put this in the file name anyways, we thought this is quite
  some waste of disk space.

### Parameter optimization

We will do parameter optimization on Gamma and Cost only, and perhaps
only with like three values for each. Something like (Check Jonathan's thesis
paper for details):

- Cost: 1, 10, 100
- Gamma: 0.1, 0.01, 0.001

Inside each such parameter combination, run CPSign Cross-Validate.

As a result from the parameter optimization, we get values for Efficiency and
Validity for each of the predictions, and can select the best parameter combo.

### Actual training

The actual training will be done in two steps:

- CpSign Pre-compute, which will create a sparse representation of the dataset.
- The actual computing step.
  - This could potentially be parallelised with SciPipe, since it will run some
    number (like ten) of trainings, using ACP, and then aggregate them together
    into one "aggregate" model at the end.

### Publishing of models in OpenShift (messi)

We were also discussing about how to publish the models in the end.

We think it is best to publish them as separate microservices per protein
target, so 44 separate ones.

We need to create some docker image and templates for these. We will want to
script the creation of them also, since 44 is a bit too much to create manually
by hand.

This task might go to Jonathan.

## Misc notes and links

- Samuel will re-read the [Norlinder introductory paper on CP](http://dx.doi.org/10.1021/ci5001168)

- Submission deadline in the [cheminformatics collection in frontiers](https://www.frontiersin.org/research-topics/5898/chemoinformatics-approaches-to-structure--and-ligand-based-drug-design)
is November 10
- The Journal is [Frontiers in Pharmacology](https://www.frontiersin.org/journals/pharmacology)

Some notes about calibration plot [by Staffan](https://pharmbio.slack.com/archives/C79QQNHU5/p1506582144000104),
in the chat, at 9:02, Sep 29 2017:

> @saml @jonalv ska vi ha ett möte på måndag då? för att svara på några
> frågor: Jag har presenterat mitt papper på COPA (var i sthlm i juni) som
> gjordes tillsammans med Lars och Paolo (samt ola såklart). Det finns en
> python-kod för att göra CVAP, men till pappret i november så ska jag
> implementera detta i CPSign så att det går snabbare etc. Kalibration-plot är
> ett koncept inom området bygga modeller, där kalibrerings-setet används för
> att "kalibrera" det värde/intervall som din prediktion får *efter* att
> bakomliggande maskininlärning gett ett värde för det nya exemplet. Dvs när
> ett nytt exempel predikteras så får man en `score` som är i intervallet [0, 1],
> men den faktiska prediktionen beror på kalibreringssetet och den isotoniska
> regressionen. Om ni tänker tillbaka till någon presentation som jag gjorde
> tidigare när vi var på krusenberg så visade jag två plottar över `p0` och
> `p1` som då används för att bestämma intervallet för den nya prediktionen.
> Kalibreringsplotten ska då visa hur långt `p0` och `p1` ligger ifrån varandra
> vid en given `score` som din bakomliggande ML ger dig. Bredden på intervallet
> säger något om "hur säker" prediktionen är. efficiency-plot antar jag att det
> är bredden på prediktionsintervallet som menas

## Misc links

- [CPSign Documentation](http://cpsign-docs.genettasoft.com/)
