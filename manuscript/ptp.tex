%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This is just an example/guide for you to refer to when submitting manuscripts
% to Frontiers, it is not mandatory to use Frontiers .cls files nor
% frontiers.tex  % This will only generate the Manuscript, the final article
% will be typeset by Frontiers after acceptance.
%                                              %
%                                                                                                                                                         %
% When submitting your files, remember to upload this *tex file, the pdf
% generated with it, the *bib file (if bibliography is not within the *tex) and
% all the figures.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Version 3.3 Generated 2016/11/10 %%% You will need to have the following
% packages installed: datetime, fmtcount, etoolbox, fcprefix, which are
% normally inlcuded in WinEdt. %%% In http://www.ctan.org/ you can find the
% packages and how to install them, if necessary. %%% NB logo1.jpg is required
% in the path in order to correctly compile front page header %%%

\documentclass[utf8]{frontiersSCNS} % for Science, Engineering and Humanities and Social Sciences articles
%\documentclass[utf8]{frontiersHLTH} % for Health articles
%\documentclass[utf8]{frontiersFPHY} % for Physics and Applied Mathematics and Statistics articles

%\setcitestyle{square} % for Physics and Applied Mathematics and Statistics articles
\usepackage{url,hyperref,lineno,microtype,subcaption}
\usepackage[onehalfspacing]{setspace}
%\usepackage{todonotes}
%\newcommand{\todoil}[1]{\todo[inline]{#1}}

\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{microtype}
\usepackage{letltxmacro}
\usepackage[cmintegrals,cmbraces]{newtxmath}

\usepackage{booktabs}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{tikz}
%\usepackage{enumitem}
\usepackage{multirow}
\usepackage{rotating}
\usepackage{placeins}
\usepackage[textsize=miniscule, linecolor=magenta, bordercolor=magenta,
            backgroundcolor=magenta, textwidth=1.1cm]{todonotes}

\linenumbers

\makeatletter

\ifcase \@ptsize \relax% 10pt
  \newcommand{\miniscule}{\@setfontsize\miniscule{4}{5}}% \tiny: 5/6
\or% 11pt
  \newcommand{\miniscule}{\@setfontsize\miniscule{5}{6}}% \tiny: 6/7
\or% 12pt
  \newcommand{\miniscule}{\@setfontsize\miniscule{5}{6}}% \tiny: 6/7
\fi

    \renewcommand{\@todonotes@drawMarginNoteWithLine}{%
    \begin{tikzpicture}[remember picture, overlay, baseline=-0.75ex]%
        \node [coordinate] (inText) {};%
    \end{tikzpicture}%
    \marginpar[{% Draw note in left margin
        \@todonotes@drawMarginNote{r}%
        \@todonotes@drawLineToLeftMargin%
    }]{% Draw note in right margin
        \@todonotes@drawMarginNote{l}%
        \@todonotes@drawLineToRightMargin%
    }%
    }
    \renewcommand{\@todonotes@drawMarginNote}[1]{
        \makebox[\marginparwidth][#1]{\begin{tikzpicture}[remember picture,baseline=(X.base)]%
            \node(X){\vphantom{X}};%
            \draw node[notestyle,font=\@todonotes@sizecommand,anchor=north] (inNote) at (X.north)%
                {\@todonotes@text};%
            \if@todonotes@authorgiven%
                \draw node[notestyle,font=\@todonotes@sizecommand,anchor=north] (inNote) at (X.north)%
                    {\@todonotes@sizecommand\@todonotes@author};%
                \node(Y)[below=of X]{};%
                \draw node[notestyle,font=\@todonotes@sizecommand,anchor=north] (inNote) at (X.south)%
                    {\@todonotes@text};%
            \else%
                \draw node[notestyle,font=\@todonotes@sizecommand,anchor=north] (inNote) at (X.north)%
                    {\@todonotes@text};%
            \fi%
        \end{tikzpicture}%
    }}
\makeatother
\LetLtxMacro{\oldtodo}{\todo}
\renewcommand{\todo}[1]{{\miniscule \color{magenta}\oldtodo[fancyline]{ \color{white}\textsf{#1} }}}
\newcommand{\inlinetodo}[1]{{\color{magenta}\oldtodo[inline]{\color{white}\textsf{\small#1}}}}

\def\keyFont{\fontsize{8}{11}\helveticabold }
\def\firstAuthorLast{Lampa {et~al.}} %use et al only if is more than 1 author
\def\Authors{Samuel Lampa\,$^{1}$, Jonathan Alvarsson\,$^{1}$, Staffan Arvidsson Mc Shane\,$^{1}$, Arvid Berg\,$^{1}$, Ernst Ahlberg\,$^{2}$  and Ola Spjuth\,$^{1,*}$}
% Affiliations should be keyed to the author's name with superscript numbers
% and be listed as follows: Laboratory, Institute, Department, Organization,
% City, State abbreviation (USA, Canada, Australia), and Country (without
% detailed address information such as city zip codes or street names).  If one
% of the authors has a change of address, list the new address below the
% correspondence details using a superscript symbol and use the same symbol to
% indicate the author in the author list.
\def\Address{$^{1}$Pharmaceutical Bioinformatics group, Department of Pharmaceutical Biosciences, Uppsala University, Uppsala, Sweden\\
$^{2}$Predictive Compound ADME \& Safety, Drug Safety \& Metabolism, AstraZeneca IMED Biotech Unit, M\"olndal, Sweden}
% The Corresponding Author should be marked with an asterisk Provide the exact
% contact address (this time including street name and city zip code) and email
% of the corresponding author
\def\corrAuthor{Corresponding Author}

\def\corrEmail{ola.spjuth@farmbio.uu.se}


\begin{document}

\onecolumn
\firstpage{1}

\title[Predicting Off-Target Binding Profiles with Confidence]{Predicting Off-Target Binding Profiles with Confidence using Conformal
Prediction}

\author[\firstAuthorLast ]{\Authors} %This field will be automatically populated
\address{} %This field will be automatically populated
\correspondance{} %This field will be automatically populated

\extraAuth{}% If there are more than 1 corresponding author, comment this line and uncomment the next one.
%\extraAuth{corresponding Author2 \\ Laboratory X2, Institute X2, Department
%X2, Organization X2, Street X2, City X2 , State XX2 (only USA, Canada and
%Australia), Zip Code2, X2 Country X2, email2@uni2.edu}


\maketitle


\begin{abstract}

%%% Leave the Abstract empty if your article does not require one, please see the Summary Table for full details.
%\section{}
%For full guidelines regarding your manuscript please refer to
%    \href{http://www.frontiersin.org/about/AuthorGuidelines}{Author
%    Guidelines}.
%
%As a primary goal, the abstract should render the general significance and
%    conceptual advance of the work clearly accessible to a broad readership.
%    References should not be cited in the abstract. Leave the Abstract empty if
%    your article does not require one, please see
%    \href{http://www.frontiersin.org/about/AuthorGuidelines#SummaryTable}{Summary
%    Table} for details according to article type.

%\todoil{Can you really have refs in abstract?}
%\todoil{--- No not really, the abstract should probably be completely rewritten. // jonalv}
%\todoil{--- No refs and no abbreviations. /Ola}
%Off-target pharmacology and polypharmacology has big implications on drug
%efficacy and safety, and prediction of target binding profiles for ligands is
%an important task that can aid early drug discovery \cite{Bowes2012}.
%However, available methods for ligand-based target profiling do not offer
%valid measures of confidence in predictions or well-calibrated probabilities.
%We present an approach for ligand-based target profiling using probabilistic
%predictions, delivering target profiles with valid predictions of the
%probability for the query compound to interact with each target. The
%probabilities are calculated using the Conformal Prediction methodology
%\cite{Vovk2005}, with support vector machines for modeling and chemical
%structures described by the signature molecular descriptor \cite{Faulon2003}.
%We study profiles for different sets of targets, including a subset of the
%minimal panel of 44 targets for broad early hazard assessment suggested by
%\cite{Bowes2012}, but also the applicability of larger as well as focused
%target sets. The resulting method is available as an online Web service via
%an API, and we also make the complete workflow for reproducing the study
%together with all models publicly available.

\label{Abstract}

Ligand-based models can be used in drug discovery to obtain an early indication
of potential off-target interactions that could be linked to adverse
effects. Another application is to combine such models into a panel,
allowing to compare  and search for compounds with similar profiles. Most
contemporary methods and implementations however lack valid measures of
confidence in their predictions, and only provide point predictions. We here
describe a methodology that uses Conformal Prediction for predicting
off-target interactions, with models trained on data from 31 targets in the
ExCAPE-DB dataset selected for their utility in broad early hazard
assessment. Chemicals were represented by the signature molecular descriptor
and support vector machines were used as the underlying machine learning
method. By using conformal prediction, the results from predictions come in
the form of confidence p-values for each class. The full pre-processing and
model training process is openly available as scientific workflows on GitHub,
rendering it fully reproducible. We illustrate the usefulness of the
developed methodology on a set of compounds extracted from DrugBank. The
resulting models are published online and are available via a graphical web
interface and an OpenAPI interface for programmatic access.
%\todo{Push more on workflow as a method?}
%SL: I think we do it enough now, don't we? // SL

\tiny
 \keyFont{ \section{Keywords:} target profiles, predictive modelling, conformal prediction, machine learning, off-target, adverse effects} %All article types: you may provide up to 8 keywords; at least 5 are mandatory.
\end{abstract}

\section{Introduction} \label{Introduction}

%Introduce off target binding as a problem, and the value of predictions
Drug-target interactions are central to the drug discovery
process~\cite{Yildirim:2007vh}, and is the subject of study for the field of
chemogenomics~\cite{Bredel2004}, which has emerged and grown over the last
few decades. Drugs commonly interact with multiple
targets~\cite{hopkins2008network}, and off-target pharmacology as well as
polypharmacology have important implications on drug efficacy and
safety~\cite{Peters:2013yg,Ravikumar:2018qd}. Organizations involved in drug
discovery, such as pharmaceutical companies and academic institutions, use
many types of experimental techniques and assays to determine target
interactions, including in vitro pharmacological profiling~\cite{Bowes2012}.
However, an attractive complementary method is to use computational (in
silico) profiling of binding profiles for
ligands~\cite{Cereto-Massague:2015px}, which also opens the possibility to
predict hypothetical compounds. A common approach to the target prediction
problem is to use a panel of structure-activity relationship (QSAR) models,
with one model per target~\cite{HanschQSAR}, where chemicals in a knowledge
base with known interaction values (numerical or categorical) are described
numerically by descriptors, and a statistical learning model is trained to
predict numerical values (regression) or categorical values (classification)
for new compounds. The recent increase in the number of available SAR data
points in interaction databases such as ChEMBL~\cite{Gaulton:2017tm} and
PubChem~\cite{Wang:2017cy} makes it feasible to using ligand-based models to
predict not only targets but also panels of targets. Several methods and
tools are available for target prediction and for constructing and using
target profiles.
%
Bender \textit{et al}. use a Bayesian approach to train models for 70
selected targets and use these for target profiling to classify adverse drug
reactions~\cite{Bender:2007ib}.
%
Chembench is a web-based portal, which, founded in 2008 is one of the first
publicly available integrated cheminformatics web portals. It integrates a
number of commercial as well as open source tools for, dataset creation,
validation, modelling and validation. It also supports building ensembles of
models, for multiple targets~\cite{Walker2010,Capuzzi2017}.
%
The Online chemical modeling environment (OCHEM), is a web-based platform
that intends to serve as multi-tool platform where users can select among the
many available alternative in terms of tools and method, for all of the steps
of creating a predictive model, such as data search, selection of descriptors
and machine learning model, as well as assessment of the resulting
model. OCHEM also encourages tool authors to contribute with their own tools
to be integrated in the platform~\cite{Sushko2011}.
%
Yu \textit{et al}. use Random Forest (RF) and Support Vector Machines (SVM) to predict
drug-target interactions from heterogeneous biological data~\cite{Yu:2012ol}.
%
TargetHunter~\cite{Wang:2013le} is another online tool that uses chemical
similarity to predict targets for ligands, and show how training models on
ChEMBL data can enable useful predictions on examples taken from PubChem
bioassays.
%
Yao \textit{et al}. describe TargetNet~\cite{Yao:2016ij}, a web service for
multi-target QSAR models; an online service that uses Na\"ive Bayes.
%
The polypharmacology browser~\cite{Awale:2017is} is a web-based target
prediction tool that queries ChEMBL bioactivity data using multiple
fingerprints.

We observe three important shortcomings among previous works. Primarily, available
methods for ligand-based target profiling often do not offer valid measures of
confidence in predictions, leaving the user uncertain about the usefulness of
predictions. Secondly, the majority of the web tools lack an open and
standardized API, meaning that it is not straightforward (and in most cases not
possible at all) to consume the services programmatically, e.g. from a
script or a scientific workflow tool such as KNIME~\cite{Mazanetz:2012gy}.
Thirdly, previous works do not publish the preprocessing and modeling
workflows in reproducible formats, rendering it hard to update the models as
data changes, and limits the portability of methods. In fact, most
implementations are only accessible from a website without the underlying
implementations being openly available for inspection.

We here present an approach for ligand-based target profiling using a
confidence framework, delivering target profiles with confidence scores for
the predictions of whether a query compound interacts with each target. The
confidence scores were calculated using the Conformal Prediction methodology
(CP)~\cite{Vovk2005}, which has been successfully demonstrated in several
recent
studies~\cite{Cortes-Ciriano:2015ec,Norinder:2014fe,Forreryd:2018kb,Norinder:2016qf}.
In particular, for a good introduction to the Conformal Prediction
methodology, we recommend~\cite{Gammerman2007}, and for a good introduction
to Conformal Prediction in the context of cheminformatics, we
recommend~\cite{Norinder:2014fe}.
%
The goal of this study was to create an automated and reproducible approach for
generating a predicted target profile based on QSAR binding models, with the models
making up the profile published online as microservices and the profile
accessible from a web page. Although the models give a confidence measure we
also set out to evaluate them on a test set to see how well they performed on
representative data. We exemplified the process by creating a profile for the
targets for broad early hazard assessment as suggested by Bowes \textit{et
al.}~\cite{Bowes2012}.

\begin{table}[p]
\small
\centering
\caption{The panel of targets used in this study, identified by gene symbol.
Actives and non-actives refer to the number of ligand interactions marked as
active and non-active in ExCAPE-DB. The labels `included' and `not included'
to the left, for the two row ranges, indicate whether targets did pass the
filtering criteria of at least 100 actives and 100 non-actives, to be
included.}
\label{tbl:targets}
\begin{tabular}{crrrrcl}
\toprule
&             &         & Non-actives          & Non-actives         &                & \\
&             &         & (before adding       & (after adding       &                & \\
&             &         & assumed non-actives  & assumed non-actives & Assumed non-   & \\
& Gene symbol & Actives & \& deduplication)    & \& deduplication)   & actives added  & Remarks \\
\midrule
\multirow{31}{*}{\begin{turn}{90}\textsc{Included}\end{turn}}
&    ACHE    &       3\,160  &       1\,152      &   5\,824   & \checkmark      &       \\
&    ADORA2A &       5\,275  &       593         &   10\,092  & \checkmark      &       \\
&    ADRB1   &       1\,306  &       149         &   2\,544   & \checkmark      &       \\
&    ADRB2   &       1\,955  &       342\,282    &   341\,925 &       &       \\
&    AR      &       2\,593  &       4\,725      &   4\,866   & \checkmark      &       \\
&    AVPR1A  &       1\,055  &       321\,406    &   321\,098 &       &       \\
&    CCKAR   &       1\,249  &       132         &   2\,458   & \checkmark      &       \\
&    CHRM1   &       2\,776  &       417\,549    &   358\,330 &       &       \\
&    CHRM2   &       1\,817  &       152         &   3\,440   & \checkmark      &       \\
&    CHRM3   &       1\,676  &       144         &   3\,234   & \checkmark      &       \\
&    CNR1    &       5\,336  &       400         &   10\,220  & \checkmark      &       \\
&    CNR2    &       4\,583  &       402         &   8\,676   & \checkmark      &       \\
&    DRD1    &       1\,732  &       356\,201    &   355\,909 &       &       \\
&    DRD2    &       8\,323  &       343\,206    &   342\,958 &       &       \\
&    EDNRA   &       2\,129  &       124         &   4\,050   & \checkmark      &       \\
&    HTR1A   &       6\,555  &       64\,578     &   64\,468  &       &       \\
&    HTR2A   &       4\,160  &       359\,962    &   359\,663 &       &       \\
&    KCNH2   &       5\,330  &       350\,773    &   350\,452 &       &       \\
&    LCK     &       2\,662  &       283         &   5\,246   & \checkmark      &       \\
&    MAOA    &       1\,260  &       1\,083      &   2\,452   & \checkmark      &       \\
&    NR3C1   &       2\,525  &       4\,382      &   4\,804   & \checkmark      &       \\
&    OPRD1   &       5\,350  &       826         &   9\,580   & \checkmark      &       \\
&    OPRK1   &       3\,672  &       303\,335    &   303\,111 &       &       \\
&    OPRM1   &       5\,837  &       2\,872      &   11\,252  & \checkmark      &       \\
&    PDE3A   &       197     &       110         &   392      & \checkmark      &       \\
&    PTGS1   &       849     &       729         &   1\,634   & \checkmark      &       \\
&    PTGS2   &       2\,862  &       827         &   5\,162   & \checkmark      &       \\
&    SCN5A   &       316     &       119         &   624      & \checkmark      &       \\
&    SLC6A2  &       3\,879  &       218         &   7\,498   & \checkmark      &       \\
&    SLC6A3  &       5\,017  &       106\,819    &   106\,594 &       &       \\
&    SLC6A4  &       7\,228  &       382         &   13\,660  & \checkmark      &       \\
\midrule
\multirow{15}{*}{\begin{turn}{90}\textsc{Not Included}\end{turn}}
&    ADRA1A  &       1\,782  &       24          &            &       &       \\
&    ADRA2A  &       839     &       39          &            &       &       \\
&    CACNA1C &       166     &       20          &            &       &       \\
&    CHRNA1  &       -       &       -           &            &       & Not in ExCAPE-DB \\
&    CHRNA4  &       256     &       17          &            &       &       \\
&    GABRA1  &       112     &       5           &            &       &       \\
&    GRIN1   &       555     &       92          &            &       &       \\
&    HRH1    &       1\,218  &       65          &            &       &       \\
&    HRH2    &       394     &       56          &            &       &       \\
&    HTR1B   &       1\,262  &       86          &            &       &       \\
&    HTR2B   &       1\,159  &       66          &            &       &       \\
&    HTR3A   &       584     &       65          &            &       &       \\
&    KCNQ1   &       37      &       303\,466    &            &       &       \\
&    MINK1   &       929     &       8           &            &       & Synonym to KCNE1 \\
&    PDE4D   &       484     &       98          &            &       &       \\

\bottomrule
\end{tabular}
\end{table}

%%%%%%%%%%%%%%%%%%
%Methods
%%%%%%%%%%%%%%%%%%
\section{Methods} \label{Methods}

\subsection{Training data} \label{Training data}

We based this study upon data from the ExCAPE-DB dataset~\cite{Sun2017}. The
reason for this is that ExCAPE-DB combines data about ligand-target binding
from ChEMBL with similar data from PubChem, where importantly, PubChem
contains many true non-actives, which has been shown earlier to result in
better models than by using random compounds as
non-actives~\cite{Mervin2015}. The data in ExCAPE-DB has also gone through
extensive filtering and pre-processing, specifically to make it more useful
as a starting point for QSAR studies. For more details on the data filtering
and processing done in the ExCAPE-DB dataset, we refer to~\cite{Sun2017}.

A scientific workflow was constructed to automate the full data
pre-processing pipeline. The first step comprises extracting data on binding
association between ligands and targets from the ExCAPE-DB
dataset~\cite{Sun2017}, more specifically the columns Gene symbol, Original
entry ID (PubChem CID or CHEMBL ID), SMILES and Activity flag. This was
performed early in the workflow to make subsequent data transformation steps
less time-consuming, given the relatively large size of the uncompressed
ExCAPE-DB data file (18 GB). From the extracted dataset, all rows for which
there existed rows with a conflicting activity value for the same target
(gene symbol) and SMILES string, were completely removed. Also, all duplicates
in terms of the extracted information (Original entry ID, SMILES and Activity flag)
were replaced by a single entry, and thus deduplicated.
%
Note that deduplication on InChI level was already done in for the ExCAPE-DB
dataset in~\cite{Sun2017}, but since the signatures descriptor is based on
SMILES, which is a more degenerate chemical format (compounds that are unique in
InChi might not be unique in SMILES) this turns out to have resulted in some
duplicate and conflicting rows in terms of SMILES still appearing in the
dataset. Since this is a potential problem in particular if the exact same
SMILES end up in both the training and calibration or test set, we performed
this additional deduplication, on the SMILES level.
\footnote{\url{https://github.com/pharmbio/ptp-project/blob/c529cf/exp/20180426-wo-drugbank/wo\_drugbank\_wf.go\#L239-L246}}).
%
For full information about the preprocessing done by the ExCAPE-DB authors to
create the values we used, see~\cite{Sun2017}. As a help to the reader we
note that the activity flag is -- in the ExCAPE-DB dataset -- set to active
(or \texttt{A}) if the dose-response value in the binding assays was lower
than 10 ${\mu}M$ and non-active (or \texttt{N}) otherwise.

A subset of the panel of 44 binding targets as suggested in \cite{Bowes2012}
was selected for inclusion in the study. The selection was based on the
criteria that targets should have at least 100 active and at least 100
non-active compounds.  In addition some targets were excluded for which data
was not found in ExCAPE-DB. This is described in detail below.
%
Some of the gene symbols used in \cite{Bowes2012} were not found in their exact
form in the ExCAPE-DB dataset. To resolve this, PubMed was consulted to find
synonymous gene symbols with the following replacements being done:
%
\textit{KCNE1} was replaced with \textit{MINK1} which is present in ExCAPE-DB.
\textit{CHRNA1} (coding for the $\alpha1$ sub-unit of the Acetylcholine
receptor) was excluded, as it is not present in the dataset (\textit{CHRNA4},
coding for the $\alpha4$ sub-unit of the Acetylcholine receptor, is present in
the dataset). We note though, that both \textit{MINK1} and \textit{CHRNA4} were removed
in the filtering step mentioned above, since the dataset did not contain more
than 100 active and 100 non-active compounds for \textit{MINK1} nor
\textit{CHRNA}.  However, since one aim of the study is to present and publish
an automated and reproducible data processing workflow, these targets could
potentially be included in subsequent runs on later versions of the database
with additional data available.

The resulting set (named Dataset1) consists of 31 targets (marked as
``included'' in Table~\ref{tbl:targets}). For 21 of these targets, the
dataset contained less than 10\,000 non-active compounds, leading to
imbalanced datasets (marked with a \checkmark\ in the `Assumed non-actives
added' column of Table~\ref{tbl:targets}). These 21 targets are referred to
as Dataset2, and their respective target datasets were expanded with randomly
selected examples from the ExCAPE-DB dataset which were not reported to be
active for the target, thus being `assumed non-active'. The number of new
examples was chosen such that the total number of non-actives and assumed
non-actives added up to twice the number of actives, for each target
respectively. The compounds for the remaining 10 targets, which were not
extended with assumed non-actives, were named Dataset3.

In order to validate the predictive ability of the trained models, a new
dataset was created (Dataset4) by withholding 1\,000 compounds from the
ExCAPE-DB dataset, to form an external validation dataset. The compounds chosen
to be withheld were the following: i) all small molecules in DrugBank (version
5.0.11) with status ``withdrawn'', for which we could find either a PubChem ID
or a CHEMBL ID, ii) a randomly selected subset of the remaining compounds in
DrugBank 5.0.11, with status ``approved'', for which we could also find PubChem
or CHEMBL IDs, until a total number of 1\,000 compounds was reached.  No regard
was paid to other drug statuses in DrugBank such as ``investigational''.

The relation of the mentioned datasets Dataset1-4 are shown in a graphical
overview of how they were created in figure~\ref{fig:datasets}, and in
table~\ref{tbl:datasets}, which summarizes in words how each dataset was
created.

The models built were validated by predicting the binding activity against each
of the 31 targets for all compounds for which there existed known binding data
for a particular target in ExCAPE-DB. The validation was done with CPSign's
\texttt{validate} command, predicting values at confidence levels 0.8 and 0.9.

The conformal prediction methodology, in particular with the mondrian
approach, can handle differing sizes of the datasets well, and so we see no
reason to stick to the exact same number of compounds as the actives, but
instead go for a little bit more data.

% (See
% \href{https://github.com/pharmbio/ptp-project/blob/c529cf307593c40e7f822a92b224036894c95de1/exp/20180426-wo-drugbank/wo_drugbank_wf.go#L308-L328}{here}
% for workflow code).
%
All the targets, with details about their respective number of active and
non-active compounds, and whether they are included or not, are summarized in
table~\ref{tbl:targets}.

\begin{figure}[t]
%\vspace{2\baselineskip}
\begin{center}
\includegraphics[width=0.5\textwidth]{figures/datasets/datasets.pdf}
    \caption{Graphical overview over how the raw datasets used in this study
    were created. The blue funnel symbol, represents filtering steps, while
    the barrel and document symbols represent datasets. The criteria for the
    filtering steps are shown with blue text. ``A'' represents ``Actives'',
    and ``N'' represents ``Non-actives''.}
    \label{fig:datasets}
\end{center}
\end{figure}

\begin{table}[h]
\small
\centering
\caption{Summary of datasets discussed. See also figure~\ref{fig:datasets}
    for a graphical overview of how each dataset was created.}
\label{tbl:datasets}
\begin{tabular}{rll}
\toprule
& Name     & Description \\
\midrule
%\multirow{31}{*}{\begin{turn}{90}\textsc{Included}\end{turn}}
& Dataset0 & SAR data points for all 44 targets in~\cite{Bowes2012} which are available in ExCAPE-DB. \\
& Dataset1 & SAR data points for the 31 targets in Dataset0 for which there were at least 100 actives and 100 non-actives. \\
& Dataset2 & SAR data points for targets with least 10\,000 non-actives. \\
& Dataset3 & SAR data points for targets which had less than 10\,000 non-actives, thus the same \\
&          & as Dataset1 with Dataset2 excluded. \\
& Dataset4 & SAR points making up the external test, by extracting rows from ExCAPE-DB for a selected set of \\
&          & 1\,000 compounds in DrugBank (All withdrawn, and randomly sampled approved, drugs,\\
&          & until reaching 1000 drugs). \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Conformal prediction}
Conformal Prediction (CP)~\cite{Vovk2005} provides a layer on top of
existing machine learning methods and produces valid prediction regions for test
objects. This contrasts to standard machine learning that delivers point
estimates. In conformal prediction a prediction region contains the true
value with probability equal to a selected significance level $\epsilon$. Such
a prediction region can be obtained under the assumption that the observed data
is exchangeable. An important consequence is that the size of this region directly
relates to the `strangeness' of the test example, and is an alternative to the
concept of a model's `applicability domain'~\cite{Norinder:2014fe}. For
the classification case, a prediction is represented as a set of p-values (one for each
class), and in the Mondrian setting the classes are handled independently,
which has attractive properties when dealing with imbalanced
datasets~\cite{Norinder:2017qc,Sun:2017qm}. 

In this study we used the Mondrian conformal prediction implementation in the
software CPSign~\cite{CPSignDocs}, leveraging the
liblinear SVM implementation~\cite{fan2008liblinear} together with the
signatures molecular descriptor~\cite{faulon2003signature}.  This descriptor is
based on the neighboring of atoms in a molecule and has been shown to work
well for QSAR studies~\cite{lapins2018confidence,Alvarsson:2016pw} and for
ligand-based target prediction~\cite{alvarsson2014ligand}. Signatures were
generated with height 3, which means that molecular subgraphs including all atoms
of distance 3 from initial atoms, are generated. Support vector
machines is a machine learning algorithm which is commonly used in QSAR
studies~\cite{norinder2003support,zhou2011qsar} together with molecular
signatures and similar molecular descriptors, \textit{e.g.}, the extended
connectivity fingerprints~\cite{rogers2010extended}. 
As nonconformity measure we used the distance between the classifier's 
decision surface and the test object, as previously described 
by~\cite{eklund2015application}. 
In order to not use the assumed non-active compounds in Dataset2 in the
calibration step in the Conformal Prediction method, these additional compounds
were treated separately, by providing them to the CPSign software with the
\texttt{--proper-train} parameter, see the CPSign
documentation~\cite{CPSignDocs}.


\subsection{Hyper-parameter tuning}
For each of the 31 targets in Dataset 1, a parameter sweep was run to find the optimal value
of the cost parameter of liblinear, optimizing modeling efficiency using
10-fold cross validation. The training approach used an Aggregated Conformal
Predictor (ACP) with 10 aggregated models.  The parameter sweep evaluated three
values for the cost parameter for each target; 1, 10 and 100. The efficiency
measure used for the evaluation was the observed fuzziness (OF) score described
in~\cite{Vovk2016} as:

\begin{equation}
OF =\frac{ 1}{m} \sum\limits_{i=1}^{m} \sum\limits_{y_i \neq y }  p_i^{\kern1pt y},		
\end{equation}

where $p_i^{\kern1pt y}$ is the p-value of the $i^{th}$ test case for class $y$, and $m$ is the number of test examples, or in our case with only two classes:

\begin{equation}
OF =  \frac
        {\quad\sum\limits_{\mathclap{\substack{\scriptscriptstyle i,\ y_i=A}}}p_i^N \, + \;\sum\limits_{\mathclap{\substack{\scriptscriptstyle i,\ y_i=N}}}p_i^A}
        {m_A + m_N}
\end{equation}

where $p_i^N$ is the $i^{th}$ p-value for class $N$, $p_i^A$ is the $i^{th}$
p-value for class $A$ and $m_A$ and $m_N$ is the number of test examples in
class $A$ and $N$ respectively. $OF$ is basically an average of the p-values for
the wrong class, \textit{i.e.}, lower fuzziness means better prediction.

To study the effect of imbalanced datasets on efficiency, we also implemented a
modified version of $OF$, due to the fact that $OF$ is influenced more
by values in the larger class in case of imbalanced datasets, referred to as
``class-averaged
observed fuzziness'' ($CAOF$) as:
\begin{equation}
CAOF = \frac
        {\quad\sum\limits_{\mathclap{\substack{\scriptscriptstyle i,\ y_i=A}}}p_i^N}
        {m_A}
       + \frac
        {\quad\sum\limits_{\mathclap{\substack{\scriptscriptstyle i,\ y_i=N}}}p_i^A}
        {m_N}
\end{equation}
with the same variable conventions as above. Where $OF$ is only an average for
the p-values in the test set, $CAOF$ averages the contribution from each class
separately, meaning that for very imbalanced cases $OF$ is mostly affected by
the larger class, while for $CAOF$, both classes contribute equally much,
regardless of their respective number of p-values.
%
%We first calculated the OF per class and divided it by the number of examples
%(compounds) in that class, and finally took the mean value of the resulting
%normalized OF values for each class.
%
%For evaluation of the OF score mentioned above, we ran cross-validation
%through CPSign's built-in crossvalidate function, with 10 folds.
%(specified to cpsign's crossvalidate and train commands using the
%\texttt{--nr-models} flag).
%
$CAOF$ was not used for cost selection, but is provided for information in the
results from the workflow.

A commonly used efficiency measure in CP is the size of the prediction region or set 
given by the predictor. In the classification setting, this is expressed as the fraction of
\textit{multi-label} predictions. This measure is denoted as the \textit{M criterion} (MC) and described
in \cite{Vovk2016}:

\begin{equation}
\text{\textit{M criterion}} = \frac{ 1}{m} \sum\limits_{i=1}^{m}  \boldsymbol{1}_{\{|\Gamma_i|>1\}}	
\end{equation}
where $\boldsymbol{1}_E$ denotes the indicator function of event $E$, returning the 
value 1 if $E$ occurs and 0 otherwise, and $\Gamma_i$ denotes the prediction set 
for test example $i$.  A smaller value is preferable. 



\begin{figure}[h!]
%\vspace{2\baselineskip}
\begin{center}
\includegraphics[width=0.63\textwidth]{figures/fig1_schematic_workflow.pdf}
    \caption{Schematic directed graph of processes and their data
    dependencies in the the modeling workflow used in the experiments in this
    study. Boxes represent processes, while edges represent data dependencies
    between processes. The direction of the edges show in which direction
    data is being passed between processes. The order of execution is here
    from top to bottom, of the graph. Each experiment contains additions and
    modifications to the workflow, but the workflow shown here, exemplifies
    the basic structure, common among most of the workflows. For more
    detailed workflow plots, see the supplementary material, figures S4 and S5.}
    \label{fig:workflow_graph_clean}
\end{center}
\end{figure}

\subsection{Modeling workflow}
Before the training, the CPSign \texttt{precompute} command was run, in order
to generate a sparse representation of each target's dataset.  ACPs consisting
of 10 models were then trained for each target using the CPSign \texttt{train}
command. The cost value used was the one obtained from the hyper-parameter
tuning. The observations added as `assumed non-actives' were not included in
the calibration set to avoid biasing the evaluation.
% (See \href{https://github.com/pharmbio/ptp-project/blob/c529cf307593c40e7f822a92b224036894c95de1/exp/20180426-wo-drugbank/wo_drugbank_wf.go#L69-L101}{here}).
The computational workflows for orchestrating the extraction of data, model
building, and the collection of results for summarizing and plotting were
implemented in the Go programming language using the SciPipe workflow library
that is available as open source software at
\href{http://scipipe.org}{scipipe.org}.  The cost values for each target are
stored in the workflow code, available on GitHub~\cite{PTPGitHub}.
A graphical overview of the modeling workflow is shown in
figure~\ref{fig:workflow_graph_clean}. More detailed workflow graphs are
available in the supplementary material, figures S4 and S5).


%%%%%%%
% Results  %
%%%%%%%
\section{Results} \label{Results}

\subsection{Published models}
Models for all targets in Dataset1 were produced in the form of portable Java
Archive (JAR) files, which were also built into similarly portable Docker
containers, for easy publication as micro services.  The model JAR files,
together with audit log files produced by SciPipe, containing trace of the
workflow (all the shell commands and parameters) used to produce them, are
available for download at~\cite{ModelsZenodo}

\subsection{Validity of models}

To check that the conformal prediction models are valid (i.e. that they predict with
an error rate in accordance to the selected significance level), calibration plots
were generated in the cross validation step of the workflow. Three example
plots, for three representative targets (the smallest, the median-sized and the
largest, in terms of compounds in ExCAPE-DB) can be seen in figure
\ref{fig:calplots}, while calibration plots for all targets can be
found in the supplementary material (figure~S1).
From these calibration plots we conclude that all models produce valid results over all
significance levels.

\begin{figure}[h!]
    \begin{minipage}[c]{0.3\textwidth}
        \setcounter{subfigure}{0} % Ensures that subfigures are labeled from a, b, c...
        \includegraphics[width=\textwidth]{figures/fig2a_pde3a_calib.pdf}
        \label{fig:calplots:a}
        \subcaption{}
    \end{minipage}
    \begin{minipage}[c]{0.3\textwidth}
    \includegraphics[width=\textwidth]{figures/fig2b_slc6a2_calib.pdf}
        \label{fig:calplots:b}
        \subcaption{}
    \end{minipage}
    \begin{minipage}[c]{0.3\textwidth}
        \includegraphics[width=\textwidth]{figures/fig2c_htr2a_calib.pdf}
        \label{fig:calplots:c}
        \subcaption{}
    \end{minipage}
    \caption{Three representative calibration plots, for models PDE3A
    (\ref{fig:calplots}a), SLC6A2  (\ref{fig:calplots}b), and HTR2A
    (\ref{fig:calplots}c), based on the smallest, the median, and the largest
    target data sets in terms of total number of compounds. The plots show
    accuracy versus confidence, for the confidence values between 0.05 and 0.95 with a step
    size of 0.05.}
    \label{fig:calplots}
\end{figure}

%\subsection{Before and after fill up with assumed non-actives}
\subsection{Efficiency of models}

The efficiency metrics OF, CAOF and MC for Dataset2 (without adding assumed
non-actives) are shown in figure~\ref{fig:21small_orig}. In
figure~\ref{fig:21small_fill}, the same metrics are shown for when all target
datasets in Dataset2 have been extended with assumed non-actives, to compensate
for these datasets' imbalanced nature.
%, after fillup with assumed non-actives for the 21 targets with less than
%10\,000 non-actives in ExCAPE-DB.
We observe that by adding assumed non-actives for small, imbalanced datasets we
improve the efficiency of models trained on these datasets. Thus, this strategy
of extending the ``small'' target datasets in Dataset2 was chosen for the
subsequent analysis workflows.

\begin{figure}[h!]
    \begin{minipage}[t]{0.62\textwidth}
        \setcounter{subfigure}{0} % Ensures that subfigures are labeled from a, b, c...
        \includegraphics[width=\textwidth]{figures/fig3a_21small_orig.pdf}
        \subcaption{Dataset2 without extending with assumed non-actives.
            Circles show individual results from the three replicate runs that were
            run, while the lines show the median value from the individual replicate
            results. Targets are here sorted by number of active compounds.}
        \label{fig:21small_orig}
    \end{minipage} \\
    \begin{minipage}[t]{0.62\textwidth}
        \includegraphics[width=\textwidth]{figures/fig3b_21small_fill.pdf}
        \subcaption{Dataset2 after extending with assumed non-actives.
            Circles show individual results from the three replicate runs that were
            run, while the lines show the median value from the individual replicate
            results. Targets are here sorted by number of active compounds.}
        \label{fig:21small_fill}
    \end{minipage}
    \begin{minipage}[t]{0.38\textwidth}
        \includegraphics[width=\textwidth]{figures/fig3c_10large.pdf}
        \subcaption{Dataset3, the 10 largest target datasets,
        which were not extended with assumed non-actives.
        Targets are here sorted by total number of compounds.}
        \label{fig:10large}
    \end{minipage}
    \caption{Efficiency metrics (M Criterion, Observed Fuzziness and
    Class-Averaged Observed Fuzziness) for Dataset1, Dataset2 and Dataset3.}
\end{figure}

%\subsection{Efficiency}
%
%In figure~\ref{fig:allmodels}, efficiency metrics Observed Fuzziness (OF), Class-Averaged OF
%(CAOF) for each model is , training time and validation.
%\inlinetodo{What can be seen from the figures?}
%
%\begin{figure}[h!]
%\includegraphics[width=\textwidth]{figures/allmodels_wo_drugbank.pdf}
%    \caption{All models with the smaller ones being filled up with assumed non-actives.}
%    \inlinetodo{Extend the figure~caption!}
%    \label{fig:allmodels}
%\end{figure}

\subsection{External validation}

In figure~\ref{fig:valplots} predicted versus observed labels for Dataset4 is
shown, for confidence levels 0.8 and 0.9 respectively. See the methods section
and in particular figure~\ref{fig:datasets} and \ref{tbl:datasets}, for
information about how Dataset4 was created. `A' denotes active
compounds and `N' denotes non-active ones. It can be seen how the number
of prediction of ``Both'' labels increase when the confidence level increases
from 0.8 to 0.9. This is as expected, as this means that fewer compounds
could be predicted to only one label, with the higher confidence level. The
number of ``Null'' predictions decreases at the higher confidence, which is
also as expected. The reason is that with a higher confidence, the predictor
must consider less probable (in the Conformal Prediction ranking sense)
predictions to be part of the prediction region. This behavior might seem
backwards, but at a higher confidence the predictor has to include less
likely predictions in order to reach the specified confidence level, which
leads to larger prediction sets. For predicted versus observed labels for
each target individually, see the supplementary material, figure S2 and S3.

\begin{figure}[h!]
\begin{minipage}[c]{0.38\textwidth}
    \setcounter{subfigure}{0} % Ensures that subfigures are labeled from a, b, c...
    \subcaption[Predicted versus observed labels, for all targets at confidence level 0.8]{
    \includegraphics[width=1\textwidth]{figures/fig4a_alltargets_0p8_valplot.pdf}
    }\label{fig:valplots:a}
\end{minipage}
\hspace{0.10\textwidth}
\begin{minipage}[c]{0.38\textwidth}
    \subcaption[Predicted versus observed labels, for all targets at confidence level 0.9]{
        \includegraphics[width=1\textwidth]{figures/fig4b_alltargets_0p9_valplot.pdf}
    }\label{fig:valplots:b}
\end{minipage}
    \caption{Predicted versus observed labels, for all targets, for the
    prediction data, at confidence level 0.8 (\ref{fig:valplots:a}) and 0.9
    (\ref{fig:valplots:b}). `A' denotes active compounds, and `N' denotes
    non-active compounds. The x-axis show observed labels (as found in ExCAPE-DB),
    while the y-axis show the set of predicted labels. The areas of the
    circles are proportional to the number of SAR data points for each
    observed label/predicted label combination. For predicted versus observed
    labels for each target individually, see the supplementary material,
    figure S2 and S3.}
    \label{fig:valplots}
\end{figure}

\subsection{Target Profile-as-a-Service}
All models based on Dataset2 were published as micro-services with REST APIs
publicly made available using the OpenAPI specification~\cite{OpenAPI} on an OpenShift~\cite{OpenShift} cluster.
A web page aggregating all the models was also created. The OpenAPI
specification is a standardization for how REST APIs are described, meaning
that there is a common way for looking up how to use the REST API of a web
service and that greatly simplifies the process of tying multiple different web
services together. It simplifies calling the services from scripts as well as
from other web pages, such as the web page (figure~\ref{fig:web}) that generates a profile image out of
the multiple QSAR models. At the top of the web page (see figure~\ref{fig:web})
is an instance of the JSME editor~\cite{Bienfait2013} in which the user can
draw a molecule. As the user draws the molecule, the web page extracts the
SMILES from the editor and sends it to the individual model services to get predictions
based on all available models. The user can set a threshold for the confidence
and get visual feedback on whether the models predict the drawn molecule as
active or non-active for each of the targets, at the chosen confidence level. In figure~\ref{fig:web} on
the right side is a graphical profile in the form of a bar plot where confidence of
the active label is drawn in the upward direction and the confidence for
non-active is drawn in the downward direction. Hovering over a bar in the plot will
give information about which model the bar corresponds to. The web page can
be accessed at \url{http://ptp.service.pharmb.io/}
%\inlinetodo{make short nice URL with pharmb.io and UU logo}.
\begin{figure}
    \begin{minipage}{0.70\textwidth}
        \setcounter{subfigure}{0} % Ensures that subfigures are labeled from a, b, c...
        \includegraphics[height=0.37\textheight]{figures/fig5a_terbutaline.png}
        \subcaption{The profile as seen on the web page (on the right hand in
        the figure). To show the profile, the user draws a molecule and
        selects a confidence level, whereafter the profile will update
        underneath. The profile is shown as a bar plot with two bars for each
        target: A purple bar, pointing in the upward direction, indicating
        the size of the p-value of the ``Active'' label, and a green bar,
        pointing downwards, indicating the size of the p-value for the
        ``Non-active'' label.}
        \label{fig:terbutaline:a}
    \end{minipage}
    \quad
    \begin{minipage}{0.25\textwidth}
        \fbox{\includegraphics[height=0.23\textheight]{figures/fig5b_terbutaline2.png}}
        \subcaption{Coloring of which parts of the molecule contributed the
        most to the prediction for ADBR2. Red color indicates the centers of
        molecular fragments (of height 3) that contributed most to the larger
        class, while blue color indicates center of fragments contributing
        most to the smaller class. In this case the larger class is ``Active'',
        which can be seen in the size of the p-values in the bottom left of
        the figure (p[A]=0.481 \textgreater p[N]=0.001).}
        \label{fig:terbutaline:b}
    \end{minipage}
    \caption{The prediction profile for Terbutaline, a known selective beta-2
    adrenergic agonist  used as a broncho\-dilator and tocolytic.
    \label{fig:web}}
\end{figure}

\subsection{Example predictions}
Using the models built without the external validation dataset (Dataset4), target
profiles were predicted for three molecules from the test set
(figure~\ref{fig:threeprofiles}), \textit{i.e.}, the profiles were made for
drugs that the models have not seen before. Figure~\ref{fig:threeprofiles:a}
shows the target profile for Tacrine, a centrally acting anticholinesterase,
with a distinct peak for the ACHE gene, as expected. Further, we note that most
other targets are predicted as non-active with high p-values (green color) or
predicted as active with relatively low p-values (purple color).
Figure~\ref{fig:threeprofiles:b} shows the target profile for Pilocarpine, a
muscarinic acetylcholine receptor M$_1$ agonist, with a target profile
consisting of mostly non-active predictions, and only two mildly active targets
(CHRM1 and LCK). We note that LCK has a similar p-value for active and
non-active. For a conformal prediction in the binary classification setting, the 
\textit{confidence} of a prediction is defined as $1 - p_2$ where $p_2$ is the
lower p-value of the two, or in other words, the p-value for the class that was
not predicted~\cite{Saunders1999}.  This means that even if a prediction has
one high p-value, its confidence and hence usefulness in a decision setting
might still be low. Figure~\ref{fig:threeprofiles:c} shows the target profile for
Pergolide, an agonist for DRD1, DRD2, HTR1A, and HTR2A which shows up as the
four highest positive predictions in the profile.

\begin{figure}
\hfill
\begin{minipage}[t]{0.3\textwidth}
    \setcounter{subfigure}{0} % Ensures that subfigures are labeled from a, b, c...
    \includegraphics[width=\linewidth]{figures/fig6a_chembl95.png}
    \subcaption{The profile for Tacrine, a centrally acting anticholinesterase,
    with a distinct peak for the ACHE gene.}
    \label{fig:threeprofiles:a}
\end{minipage}
\hfill
\begin{minipage}[t]{0.3\textwidth}
    \includegraphics[width=\linewidth]{figures/fig6b_chembl550.png}
    \subcaption{The profile for Pilocarpine, a muscarinic acetylcholine
    receptor M$_1$ agonist, with only two moderately higher peaks for positive
    prediction, CHRM1 and LCK.}
    \label{fig:threeprofiles:b}
\end{minipage}
\hfill
\begin{minipage}[t]{0.3\textwidth}
    \includegraphics[width=\linewidth]{figures/fig6c_chembl531.png}
    \subcaption{The profile for Pergolide, a DRD1, DRD2, HTR1A, and HTR2A
    agonist, which is reflected by the four highest p-values for a positive
    prediction.}
    \label{fig:threeprofiles:c}
\end{minipage}
\hfill
\caption{Profiles for a few of the removed drugs using the validation models,
    \textit{i.e.}, these molecules are not in the training sets for the models.
    The profiles are shown as bar plots with two bars for each target: A purple
    bar pointing in the upward direction, indicating the size of the p-value of
    the ``Active'' label, and a green bar pointing downwards, indicating the size
    of the p-value for the ``Non-active'' label.
    \label{fig:threeprofiles}}
\end{figure}



%%%%%%%
% Discussion  %
%%%%%%%
\section{Discussion} \label{Discussion}
The use of workflows to automate pre-processing and model training and make it
completely reproducible has several implications. Primarily, the entire process
can be repeated as data change, e.g. when new data is made available or data is
curated. In our case, the pre-processing can be re-run when a new version of
ExCAPE-DB is released, and new models trained on up-to-date data can be
deployed and published without delay. The components of the pre-processing
workflow are however general, and can be re-used in other settings as well.
Further, a user can select the specific targets that will be pre-processed, and
focus the analysis on smaller subsets without having to pre-process and train
models on all targets, which could be resource-demanding. With a modular
workflow it is also easy to replace specific components, such as evaluating
different strategies and modeling methods.

The packaging of models as JAR-files and Docker containers makes them portable and easy to
transfer and deploy on different systems, including servers or laptops on
public and private networks without cumbersome dependency management. We chose
to deploy our services inside RedHat OpenShift container orchestration system,
which has the benefit of providing a resilient and scalable service, but any
readily available infrastructure provider is sufficient. The use of OpenAPI for
deploying an interoperable service API means that the service is simple to
integrate and consume in many different ways, including being called from a web
page, (such as our reference page on \url{https://ptp.service.pharmb.io/})
but also into third party applications and workflow systems. With the
flexibility to consume models on individual level comes the power to put
together custom profiles (panels) of targets. In this work we have selected
targets based on usefulness in a drug safety setting, but it is easy to
envision other types of panels for other purposes. While there has been some
previous research on the use of predicted target
profiles~\cite{Awale:2017is,Yao:2016ij}, further research is needed to maximize
their usefulness and to integrate with other types of in vitro and in silico
measures. Our methodology and implementation facilitates such large-scale and
integrative studies, and paves the way for target predictions that can be
integrated in different stages of the drug discovery process.


\section{Conclusion} \label{Conclusion}
We developed a methodology and implementation of target prediction profiles,
with fully automated and reproducible data pre-processing and model training
workflows to build them. Models are packaged as portable Java Archive (JAR)
files, and as Docker containers that can be deployed on any system. We trained
data on 31 targets related to drug safety, from the ExCAPE-DB dataset and published
these as a predictive profile, using conformal prediction to deliver prediction
intervals for each target. The example profile is deployed as an online service
with an interoperable API.



\section{Data Availability} \label{Data Availability}

\begin{itemize}
    \item The datasets analyzed for this study can be found on Zenodo (for
        ExCAPE-DB)~\cite{ExcapeDBZenodo}, and on the DrugBank website (for
        DrugBank datasets)~\cite{DrugBankWebsite}.
    \item The data (i.e. the predictive models) generated in this study are
        available on Zenodo at~\cite{ModelsZenodo}.
    \item Source code used in this study, is available on GitHub
        at~\cite{PTPGitHub}.
\end{itemize}

\newpage

\section{Abbreviations} \label{Abbreviations}

\begin{itemize}
    \item A: Active
    \item ACP: Aggregated Conformal Predictor
    \item CAOF: Class-Averaged Observed Fuzziness
    \item CP: Conformal Prediction
    \item JAR: Java Archive (A file format)
    \item MC: M Criterion (Fraction of multi-label predictions)
    \item N: Non-active
    \item OF: Observed Fuzziness
    \item QSAR: Quantitative Structure-Activity Relationship
    \item RF: Random Forest
    \item SMILES: Simplified molecular-input line-entry system (A text-based representation of chemical structures)
    \item SVM: Support Vector Machines
\end{itemize}


\section{Conflict of Interest Statement}
%All financial, commercial or other relationships that might be perceived by
%the academic community as representing a potential conflict of interest must
%be disclosed. If no such relationship exists, authors will be asked to confirm
%the following statement:
OS, JA, AB, and SA are involved in Genetta Soft AB, a Swedish based company
developing the CPSign software.


\section{Author Contributions}
OS conceived the study. OS, JA, SA and SL designed the study, interpreted
results, and wrote the manuscript. SL implemented the workflow and carried out
the analysis. SA extended CPSign with new features. JA, SA and AB contributed
with model deployment and APIs. EA contributed with expertise in target
profiles and modeling. All authors read and approved the manuscript.


%The Author Contributions section is mandatory for all articles, including
%articles by sole authors. If an appropriate statement is not provided on
%submission, a standard one will be inserted during the production process. The
%Author Contributions statement must describe the contributions of individual
%authors referred to by their initials and, in doing so, all authors agree to be
%accountable for the content of the work. Please see
%\href{http://home.frontiersin.org/about/author-guidelines#AuthorandContributors}{here}
%for full authorship criteria.

\section{Funding}
%Details of all funding sources should be provided, including grant numbers if
%applicable. Please ensure to add all necessary funding information, as after
%publication this is no longer possible.
This study was supported by OpenRiskNet (Grant Agreement 731075), a project
funded by the European Commission under the Horizon 2020 Programme.

\section{Acknowledgments}
The computations were performed on resources provided by SNIC through Uppsala
Multidisciplinary Center for Advanced Computational Science (UPPMAX) under
Project SNIC 2017/7-89.
%This is a short text to acknowledge the contributions of specific colleagues,
%institutions, or agencies that aided the efforts of the authors.

\bibliographystyle{unsrt}
\bibliography{ptp}
\end{document}


