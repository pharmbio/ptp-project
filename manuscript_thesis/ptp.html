<h1 id="introduction">Introduction</h1>
<p>Off-target pharmacology and polypharmacology has big implications on drug efficacy and safety, and prediction of target binding profiles for ligands is an important task that can aid early drug discovery <span class="citation"></span>. However, available methods for ligand-based target profiling do not offer valid measures of confidence in predictions or well-calibrated probabilities. We present an approach for ligand-based target profiling using probabilistic predictions, delivering target profiles with valid predictions of the probability for the query compound to interact with each target. The probabilities are calculated using the Conformal Prediction methodology <span class="citation"></span>, with support vector machines for modeling and chemical structures described by the signature descriptor <span class="citation"></span>. We study profiles for different sets of targets, including a subset of the minimal panel of 44 targets for broad early hazard assessment suggested by <span class="citation"></span>, but also the applicability of larger as well as focused target sets.</p>
<h1 id="methods">Methods</h1>
<p>The dataset used for information about binding association between ligands and targets, was ExcapeDB. An extraction of only the columns for Gene name, SMILES and Activity flag was performed in order to make subsequent data traformation steps easier to implement and faster to process, given the relative large size of the uncomplressed ExcapeDB data file (18 GB).</p>
<p>Also, from this extracted dataset, duplicate rows were removed. Also, all rows for which there were rows with a conflictnig value for the activity flag, were completely removed.</p>
<p>As targets, a subset of the panel of 44 targets as suggested in <span class="citation"></span> was used. Specifically, this list of 44 targets was filtered to remove any target for which the dataset contained less than 100 data points about either associated or non-associated ligands respectively. Thus, only targets with at least 100 associated, and at least 100 non-associated, compounds, where kept.</p>
<p>Some of the gene ids used in <span class="citation"></span> was not found in their exact form in the ExcapeDB dataset. To resolve this, we did PubMed entrez searches, to find synonymous gene IDs. The following replacements of gene ids were done:</p>
<p>KCNE1 was replaced with MINK1 which is available in ExcapeDB. CHRNA1 (coding for the <span class="math inline"><em>α</em>1</span> subunit of the Acetylcholine receptor) is skipped, as it was not found in the dataset. CHRNA4 (coding for the <span class="math inline"><em>α</em>4</span> subunit of the Acetylcholine receptor) is included though.</p>
<p>Both MINK1 and CHRNA4 were removed in the filtering step mentioned above, since the dataset did not contain more than 100 active and 100 non-active compounds for neither MINK1 nor CHRNA4.</p>
<p>The resulting panel consists of 31 targets, represented by the following gene IDs in the ExcapeDB dataset, and througout this article: PDE3A, SCN5A, CCKAR, ADRB1, PTGS1, CHRM3, CHRM2, EDNRA, MAOA, LCK, PTGS2, SLC6A2, ACHE, CNR2, CNR1, ADORA2A, OPRD1, NR3C1, AR, SLC6A4, OPRM1, HTR1A, SLC6A3, OPRK1, AVPR1A, ADRB2, DRD2, KCNH2, DRD1, HTR2A, CHRM1.</p>
<p>For 21 of these targets, the dataset contained less than 100 non-active compounds, leading to imbalanced datasets. These 21 target genes are: PDE3A, SCN5A, CCKAR, ADRB1, PTGS1, CHRM3, CHRM2, EDNRA, MAOA, LCK, PTGS2, SLC6A2, ACHE, CNR2, CNR1, ADORA2A, OPRD1, NR3C1, AR, SLC6A4 and OPRM1. For these 21 targets, we filled up their respective datasets with randomly selected examples from the raw dataset which were not reported to be active for this target, thus being “assumed non-active”. The amount of such assumed non-active compounds were chosen to be twice the number of actives for each target in question.</p>
<h2 id="software-for-training-and-cross-validation">Software for training and cross-validation</h2>
<p>The software for training and cross-validation was the cpsign software <span class="citation"></span> previously developed in the group. Certain modifications were done based on needs identified in the project, which have been merged into the latest release of the cpsign software. cpsign is a commercial software, available from genettasoft.com [LINK].</p>
<p>The computational workflows for orchestrating the extraction of data, running cpsign, and the collection of results for summarization and plotting, were implemented in the Go programming language, using the SciPipe workflow library developed in the group, and which is available as open source software on scipipe.org and github.com/scipipe/scipipe [LINK].</p>
<h2 id="choice-of-cost-value-for-liblinear">Choice of cost value for liblinear</h2>
<p>For each of the 31 targets, we ran a parameter sweep to find the value of the cost parameter of liblinear that gave the best efficiency measure. The efficiency measure we used, was a slightly modified version of observed fuzziness (OF) scores as described in <span class="citation"></span>. Instead of using an overall OF, which would have been been influenced more by values in the larger class in case of imbalanced datasets, we first calculated the OF per class and divided it by the number of examples (compounds) in that class, and finally took the mean value of the resulting normalized OF values for each class. In other words, we could thus call our measure a “class-normalized observed fuzziness” (CNOF).</p>
<p>The parameter sweep evaluated three values for the cost parameter, for each target; 1, 10 and 100.</p>
<p>for evaluation of the CNOF score mentioned above, we ran cross-validation through cpsign’s built-in crossvalidate function, with 10 folds. The training approach in the crossvalidation was the same as the one used to build the final model: Aggregated Conformal Prediction (ACP) with 10 aggregated models (specified to cpsign’s crossvalidate and train commands using the <code>–nr-models</code> flag)</p>
<h2 id="building-final-models">Building final models</h2>
<p>Before the final training the cpsign precompute command was run, in order to generate a sparse representation of the dataset for the final training. The final models were then built using the cpsign train command. The cost value used is the one obtained from the cross validation, as described above. The training type was – just as in the cross validation for selecting the cost value – Aggregated Conformal Prediction (ACP), with 10 aggregated models.</p>
<h1 id="conflict-of-interest-statement" class="unnumbered">Conflict of Interest Statement</h1>
<p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
<h1 id="author-contributions" class="unnumbered">Author Contributions</h1>
<h1 id="funding" class="unnumbered">Funding</h1>
<h1 id="acknowledgments" class="unnumbered">Acknowledgments</h1>
<h1 id="supplemental-data" class="unnumbered">Supplemental Data</h1>
<h1 id="references" class="unnumbered">References</h1>
<h1 id="figure-captions" class="unnumbered">Figure captions</h1>
